<!DOCTYPE html>

<html lang="en">

<head>
  <title>Chapter 2: Linear Regression with One Feature | An Introduction to Artificial Intelligence and Machine Learning Algorithms</title>

  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="preconnect" href="https://fonts.gstatic.com">
  <link rel="shortcut icon" href="../../assets/images/favicon.png" type="image/x-icon">

  <link rel="stylesheet" href="../../assets/css/bootstrap.min.css">
  <link rel="stylesheet" href="../../assets/css/series.css">

  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:400,700,800,300" type="text/css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:wght@100;200;300;400&family=Roboto:wght@300;400;500&display=swap" type="text/css">
  <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=PT+Serif:ital,wght@0,400;0,700;1,400;1,700&display=swap">

  <script>
    MathJax = {
      tex: { inlineMath: [['$', '$'], ['\\(', '\\)']] },
      svg: { fontCache: 'global' }
    };
  </script>

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js" async></script>

  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());
    gtag('config', 'UA-90367614-1');
  </script>

  <script src="https://www.googletagmanager.com/gtag/js?id=UA-90367614-1" async></script>
  <script src="https://kit.fontawesome.com/ddc5710cc6.js"></script>
</head>

<body data-spy="scroll" data-target=".site-navbar-target" data-offset="300" data-aos-easing="slide" data-aos-duration="800" data-aos-delay="0" cz-shortcut-listen="true">
  <div class="sticky-wrapper" style="height: 95px;">
    <div class="site-navbar site-navbar-target">
        <div class="row align-items-center" style="margin-right: 0 !important;">
          <div class="col-12">
            <nav class="site-navigation text-right">
                <a class="home-icon-link" href="../../index.html" class="pl-3 pr-3"><span class="fas fa-home" style="color: white !important;"></span></a>
                <ul class="site-menu main-menu ">
                  <li><a href="https://twitter.com/BrandonJGrenier" class="pl-3 pr-3"><span class="fab fa-twitter"></span></a></li>
                  <li><a href="https://github.com/BrandonJohnGrenier" class="pl-3 pr-3"><span class="fab fa-github"></span></a></li>
                  <li><a href="https://linkedin.com/in/brandon-grenier" class="pl-3 pr-3"><span class="fab fa-linkedin-in"></span></a></li>
                </ul>
            </nav>
          </div>
        </div>
    </div>
  </div>

  <div class="site-section book-section">
    <div class="container">
      <div class="row">
        <div class="col-md-12 mb-3 mt-3 book-title">
          <h1 class="text-white text-uppercase mt-3 book-title-font">AN INTRODUCTION TO ARTIFICIAL INTELLIGENCE AND MACHINE LEARNING ALGORITHMS</h1>
          <p class="text-white mb-5 text-uppercase" style="font-family: Open Sans !important; font-weight: 100 !important; font-size: 22px !important; opacity: 0.8;">Brandon John Grenier</p>
        </div>
      </div>
    </div>
  </div>

  <div class="site-section" style="background-color: #FFF; padding-top: 60px;">
    <div class="container chapter-container">
      <div class="row">
        <div class="col-md-12">

        <div class="row mb-5" style="margin-top: -25px;">
          <div class="col-md-6 text-right pr-2"><a href="chapter01.html">&laquo; Chapter 1</a> &nbsp;&bull;</div>
          <div class="col-md-6 text-left pl-0"><a href="chapter03.html">Chapter 3 &raquo;</a></div>
        </div>

        <h1 class="heading">Chapter 2: Linear Regression with One Feature</h1>

        <p>
          Linear regression is one of the simplest and most well understood algorithms in machine learning, and the
          first regression model algorithm that we’ll cover in detail. Regression models are used in supervised learning
          strategies to predict continuous values; in this chapter we’ll develop a linear regression algorithm to predict
          the price of real estate in Melbourne, Australia.
        </p>

        <p>
          As a practical introduction to linear regression, we’ll begin by making predictions <em>intuitively</em> – no math or algorithms
          will be involved, just a bit of guesswork. We’ll then formalize this intuition by introducing key machine learning concepts, mathematics
          and algorithms that underpin linear regression. By the end of this chapter, you will have all of the tools you need to build your own linear
          regression machine learning algorithm.
        </p>

        <p>
          As hinted by the chapter title, we’re going to build a linear regression algorithm that uses a single variable, or
          <em>feature</em>. Linear regression that uses a single variable is referred to as <strong>univariate linear regression</strong>.
          Due to its simplicity, univariate linear regression serves as a fantastic technical introduction to foundational machine learning
          concepts, models and mathematics. Although the machine learning algorithms in upcoming chapters will increase in
          complexity and sophistication, they effectively iterate on the foundations we introduce in this chapter.
        </p>




          <a name="sec-1"></a>
          <h2>Intuitive Linear Regression</h2>
          <p>
            The first prediction we’re going to make using linear regression will be an intuitive one – there’s no math
            or algorithms involved at this point, just a bit of guesswork. As a consequence of this guesswork our predictions
            will be <em>reasonable</em>, but not perfect - we’ll improve on our predictive ability as we formalize our intuition.
          </p>

          <h3>Predicting the price of a home in Melbourne, Australia</h3>
          <p>
            Let’s assume that you would like to buy a 150 square meter home in Melbourne’s inner city suburb of Richmond.
            You’ve done some homework and collected data from twelve recent sales in the area - each data point consists of
            a home’s sale price and its size in square metres.
          </p>
          <p>
            Based on this data, you want to predict how much it might cost to buy a 150 square meter home in Richmond. For
            the sake of this exercise, we’ll assume that the price of a home is only dependent on a single <em>feature</em> - the
            size of the home.
          </p>
          <p>
            Let’s start with a simple method to figure out how much it might cost to buy a 150m<sup>2</sup> home in Richmond.
          </p>

          <h3>Step 1: Plot the data</h3>
          <p>
          As a first step, we’ll plot all of the sales data onto a graph. Figure 1 below presents
          a graph of the sales data, with house sizes (in m<sup>2</sup>) on the horizontal <em>x axis</em> and house
          prices on the vertical <em>y axis</em>.
          </p>

          <figure>Figure 1: House price as a function of house size</figure>
          <img src="images/chapter2/figure1.png"></img>

          <h3>Step 2: Fit the data</h3>
          <p>
            Now that our sales data is plotted on a graph, we can simply use our best judgement to draw a straight red line that fits
            the data reasonably well. Figure 2 below presents our red line overlaying the sales data.
          </p>

          <figure>Figure 2: Using judgement to draw a straight line that fits our housing data</figure>
          <img src="images/chapter2/figure2.png"></img>

          <h3>Step 3: Make a prediction</h3>
          <p>
            To predict the price of a 150m<sup>2</sup> home in Richmond, draw a vertical line from the 150m<sup>2</sup> value located on the x axis
            until it intersects with the red line we drew in step 2. From the intersection come across to the y axis to get
            the predicted price of a 150m<sup>2</sup> home. Figure 3 below provides you with a visual demonstration of our prediction using
            green dashed lines.
          </p>

          <figure>Figure 3: Predicting the price of a 150m<sup>2</sup> home in Richmond</figure>
          <img src="images/chapter2/figure3.png"></img>

          <p>
            Based on the sales data you collected, we can predict that a 150m<sup>2</sup> house in Richmond will cost
            approximately <strong>$900,000</strong> to purchase.
          </p>

          <p>
            Let’s quickly summarize the four steps we just took to make this prediction:
          </p>

          <ol>
            <li>We collected data</li>
            <li>We plotted the data</li>
            <li><em>We drew a straight line that best fit the data</em></li>
            <li>We used the line to make a prediction – an educated guess in the absence of data</li>
          </ol>

          <p>
            In step 3, we used our judgement to draw a straight line to fit the data as best as we could. For the remainder of
            this chapter, we’ll go on a journey to replace this <em>judgement</em> with <em>data-driven algorithms</em> which will
            ultimately perform the same function, but do so with far more accuracy.
          </p>


          <a name="sec-2"></a>
          <h2>The Hypothesis Function</h2>

          <p>
            The <strong>hypothesis function</strong> is a term that describes any mathematical function that is used to fit, or model
            your data. Problems spaces like population growth and infection rates may best be modelled with <em>exponential functions</em>;
            predicting yearly fluctuations in global temperature could potentially be modelled with <em>sinusoidal functions</em>;
            predicting earthquake behavior could be modelled with <em>logarithmic functions</em>.
          </p>

          <h3>The Hypothesis Function for Linear Regression</h3>

          <p>
            A <em>linear function</em> is optimal for modelling linear relationships like our home sales data, and well suited as our
            linear regression hypothesis function. Our current problem space only involves one variable - the size of a home.
            Consequently, our linear regression hypothesis function only needs to support one variable, and is defined as:
          </p>

          <p><strong>h(x) = &Theta;<sub>0</sub> + &Theta;<sub>1</sub>x</strong></p>

          <p>
            The symbol &Theta; is called theta, you’ll see references to theta throughout machine learning.
          </p>

          <h3>The Goal of Linear Regression</h3>
          <p>
            Now that we’ve defined the hypothesis function for linear regression, we have enough context to define
            the <em>goal</em> of linear regression:
          </p>

          <blockquote>
            Given a training set, produce a hypothesis function h so that h(x) is a good predictor for y.
          </blockquote>

          <p>
            In other words, linear regression aims to produce a hypothesis function whose <em>predictions</em> match <em>observations</em>
            as closely as possible. It does this by identifying the best values for <strong>&Theta;<sub>0</sub></strong> and
            <strong>&Theta;<sub>1</sub></strong> so that the hypothesis function minimizes the difference between predictions and
            observations. We can concretely define a <strong>good predictor</strong> as a hypothesis function that most effectively <em>minimizes the difference</em> between predicted
            values <strong>h(x)</strong> and observed values <strong>y</strong>, for all values of <strong>x</strong> in a
            training set. The smaller the difference, the better the predictor; the larger the difference, the poorer the predictor.
          </p>

          <h4>Reader Tip: Linear Function Review</h4>
          <p>
            We’ve included a review of linear functions and a few visual examples of functions that are commonly used to model
            data in <a href="appendixA.html">Appendix A</a>. If it’s been a while since you’ve last used linear functions we
            recommend that you read Appendix A before you move on to the next section.
          </p>



          <a name="sec-3"></a>
          <h2>The Cost Function</h2>

          <p>
            The <strong>cost function</strong> allows us to objectively measure how well a hypothesis function acts as a <em>good predictor</em> for a given
            training set. It does this by computing the average difference between predicted values <strong>h(x)</strong> and
            observed values <strong>y</strong>, for all values of <strong>x</strong> in a training set.
          </p>
          <p>
            Instead of simply defining the cost function, we'll derive the cost function so that you can get an appreciation for
            its behavior and mechanics.
          </p>

          <h3>Deriving The Cost Function</h3>
          <br/>
          <p>
          <strong>Step 1:</strong> For each instance in the training set, calculate the difference between the predicted
          value h(x) and the observed value y.
          </p>

          $$h(x_{i}) - y_{i}$$

          <p>
          The subscript <strong><em>i</em></strong> refers to a specific training <em>instance</em> in the training set.
          </p>

          <p><strong>Step 2:</strong> Sum up all the differences.</p>

          $$\displaystyle \sum _{i=0}^m \left (h (x_{i}) - y_{i} \right)$$

          <p>
            The variable <strong>m</strong> refers to the size of the training set.
          </p>

          <p><strong>Step 3:</strong> Divide the total difference by the size of the training set.</p>

          $$\dfrac {1}{m} \displaystyle \sum _{i=0}^m \left (h (x_{i}) - y_{i} \right)$$

          <p>
            What we’ve just derived is a perfectly usable cost function, but we’re going to make two modifications so that it’s
            simpler to implement in practice.
          </p>

          <p>
            First, we are going to square the error component (the difference between the predicted value <strong>h(x)</strong> and observed value <strong>y</strong>).
            Squaring always ensures that we have a positive number; for example 4<sup>2</sup> and -4<sup>2</sup> are both equal to 16. A
            programmatic implementation of the cost function only cares about the magnitude of error - getting rid of negatives removes a bit
            of complexity in dealing with both positive and negative numbers.
          </p>

          <p>
            Second, the entire cost function is multiplied by ½ so that the function remains consistent when derivatives of
            this function are taken. Since the derivative of x<sup2</sup> is 2x, multiplying by ½ negates the effect of the exponent.
          </p>

          <p>
            This is the formal definition of the cost function, which is also referred to as the squared error function or mean
            error function:
          </p>

          $$\dfrac {1}{2m} \displaystyle \sum _{i=0}^m \left (h (x_{i}) - y_{i} \right)^2$$

          <p>
            Finally, we substitute the reference to our hypothesis function <strong>h(x<sub>i</sub>)</strong> with the linear regression hypothesis function that we
            introduced previously. This is the fully expanded cost function that we will use in the linear regression algorithm:
          </p>

          $$J(\theta_0, \theta_1) = \dfrac {1}{2m} \displaystyle \sum _{i=0}^m \left (\theta_0 + \theta_1x_{i} - y_{i} \right)^2$$

          <p>
            The cost function is conventionally defined as <strong>J</strong>. The linear regression algorithm will identify values
            for Θ<sub>0</sub> and Θ<sub>1</sub> so that our cost function J(Θ<sub>0</sub>, Θ<sub>1</sub>) produces the smallest possible value. By way of convention, we say
            that we want our machine learning algorithm to <em>minimize</em> J(Θ<sub>0</sub>, Θ<sub>1</sub>).
          </p>

          <h3>The Cost Function in Practice</h3>
          <p>
            To get a better appreciation of how the cost function works, we’ll run through an exercise to calculate and compare the
            cost function of two different linear regression hypothesis functions to find out which one would act as the
            better predictor.
          </p>

          <p>
            In figure 5 below, I’ve plotted the function <strong>h(x) = 3 + 11x</strong>, the function <strong>h(x) = 1 + 5x</strong> and a
            training set consisting of five data points. The data points in our training set are as follows:
          </p>

          <table>
            <thead><tr><td>x</td><td style="text-align: center;">y</td></tr></thead>
            <tr><td>5</td><td>30</td></tr>
            <tr><td>6</td><td>40</td></tr>
            <tr><td>7</td><td>50</td></tr>
            <tr><td>8</td><td>60</td></tr>
            <tr><td>9</td><td>70</td></tr>
          </table>
          <br/>

          <figure>Figure 5: Comparing the predictive performance of two linear regression hypothesis functions</figure>
          <img src="images/chapter2/figure5.png"></img>

          <p>
            A quick inspection of this graph would suggest that that the function h(x) = 1 + 5x is a better fit for the data,
            and therefore a better predictor than the function h(x) = 3 + 11x.  Let’s compute the cost function for both of these
            hypothesis functions to get a concrete and objective answer.
          </p>

          <p>
            Table 1 and Table 2 below show the work for calculating the cost functions for each respective hypothesis function.  
          </p>

          <figure>Table 1: Calculating the cost function for h(x) = 1 + 5x</figure>
          <table>
            <thead>
            <tr>
              <td>x</td>
              <td>Predicted Value</td>
              <td>Observed Value</td>
              <td>Difference</td>
              <td>Squared Difference</td>
            </tr>
          </thead>
            <tr>
              <td>5</td>
              <td>26</td>
              <td>30</td>
              <td>-4</td>
              <td>16</td>
            </tr>
            <tr>
              <td>6</td>
              <td>31</td>
              <td>40</td>
              <td>-9</td>
              <td>81</td>
            </tr>
            <tr>
              <td>7</td>
              <td>36</td>
              <td>50</td>
              <td>-14</td>
              <td>196</td>
            </tr>
          </table>

          <figure>Table 2: Calculating the cost function for h(x) = 3 + 11x</figure>
          <table>
            <thead>
            <tr>
              <td>x</td>
              <td>Predicted Value</td>
              <td>Observed Value</td>
              <td>Difference</td>
              <td>Squared Difference</td>
            </tr>
          </thead>
            <tr>
              <td>5</td>
              <td>26</td>
              <td>30</td>
              <td>-4</td>
              <td>16</td>
            </tr>
            <tr>
              <td>6</td>
              <td>31</td>
              <td>40</td>
              <td>-9</td>
              <td>81</td>
            </tr>
            <tr>
              <td>7</td>
              <td>36</td>
              <td>50</td>
              <td>-14</td>
              <td>196</td>
            </tr>
          </table>

          <p>
            By going through this exercise, we have been able to show that J(1, 5) has a cost of 123.0 and that J(3,11) has a cost
            of 451.0. We can new objectively assert that h(x) = 1 +5x is a better predictor for our observed
            data than h(x) = 3 + 11x.
          </p>

          <p>
            Given a perfect predictor has a cost of 0, the data also suggests that there are more optimal values for Θ0 and Θ1.
            As an exercise for the reader, find values for Θ0 and Θ1 that would be a better predictor than (1, 5) and run
            through the exercise above to quantify how much better your function performs. Going through the exercise should
            demonstrate that even though the cost function might look a bit intimidating, it’s quite easy to work with.
          </p>

          <p>
            We now have the means to define our model and get feedback on its performance. The final step is to discover
            the best performing model to act as the predictor for our data. In the next section we introduce the
            gradient descent algorithm, which will provide us with the means to minimize J(Θ0, Θ1) efficiently.
          </p>


          <h2>The Gradient Descent Algorithm: Use feedback to find the best predictor</h2>

          <p>
            The gradient descent algorithm is a general purpose algorithm that has a number of practical applications
            in machine learning. It has broad applicability in machine learning as the gradient descent algorithm provides
            an efficient means to minimize functions. The cost function has provided us with the ability to quantify the
            effectiveness of a model, and with that feedback the gradient descent algorithm will find the minimal cost for our
            model – put simply, gradient descent will find the values of Θ0 and Θ1 that will act as the best predictor for
            our model.
          </p>

          <p>
            By the end of this section you should have a good understanding of how the gradient descent algorithm works, and
            appreciate how the algorithm solves minimization problems.
          </p>


          <h3>Intuitive Gradient Descent</h3>
          <p>
            Before we define the gradient descent algorithm, let’s first get an intuitive understanding of how the gradient descent
            algorithm works and appreciate its limitations. The gradient descent algorithm is effective at finding local minima -
            the smallest values of a function, in and around a local area of a function.
          </p>
          <p>
            Figure 6 below presents a function with a couple examples of the gradient descent algorithm in action:
          </p>

          <figure>Figure 6: The gradient descent algorithm - discovering minima by intuition</figure>
          <img src="images/chapter2/figure6.png"></img>

          <p>
          Imagine this function is a mountain, and you’re standing where the green star is. A storm has rolled in, and visibility
          is poor – you can only see a few steps in front of you. You need to head to the base of the mountain as soon as you
          can to ride out the storm in safety.
          </p>

          <p>
          How will you get down? The approach described below acts as a good analogy for the behavior of the gradient descent
          algorithm.
          </p>

          <ol>
            <li>You look around, and find a new location that is lower than your current location.</li>
            <li>You take a few steps in the direction of the new location and stop.</li>
            <li>From the new location, you repeat steps 1 and 2 until you can no longer find a location that is lower; in this case you’ve reached (as far as you know) the base of the mountain – the green circle in the figure.</li>
          </ol>

          <p>
          One thing you may have immediately noticed going through this exercise is that we did not reach the base of the
          mountain when we started from the green star; this is an example of a local minimum. Had we started the same exercise
          from the blue star, we would have reached the base of the mountain.
          </p>

          <p>
          The conclusion we can draw from this exercise is that the gradient descent algorithm is not well suited for minimizing
          functions that have more than one local minima, since the result you receive would be highly dependent on your
          initial starting position – you would never know if you truly minimized the function. The gradient descent
          algorithm should only be used to minimize functions that have a single, global minima.
          </p>

          <p>
          The good news is that the linear regression cost function does have a single global minima, so it’s well suited to
          be minimized by the gradient descent algorithm. We aren’t going to explain why linear regression cost functions
          have a single global minima, but we are going to present a 3D visualization of the cost function as a function of
          Θ0 and Θ1 so you can appreciate the actual terrain our gradient descent algorithm will traverse.
          </p>

          <figure>Figure 7: J(Θ0, Θ1) as a function of Θ0  and Θ1</figure>
          <img src="images/chapter2/figure7.png"></img>

          <p>
            This graph presents cost J(Θ0, Θ1) as a function of both Θ0 and Θ1, and represents the actual topology that our
            gradient descent algorithm will navigate - it’s pretty cool. In fact, all linear regression cost functions will end
            up with this convex shape, which is why we can use the gradient descent algorithm to minimize linear regression cost
            functions.
          </p>

          <p>
            High areas shown in red represent high costs, and are consequently bad predictors. Low areas in shown in blue
            represent low costs, and are consequently good predictors. The gradient descent algorithm will find the lowest point
            on this graph, which also means that it will find the best predictor.
          </p>

          <h3>The Gradient Descent Algorithm</h3>

          <p>
            While the pseudo-algorithm for walking down a mountain was quite straightforward, transcribing this concept
            algorithmically is a little less straightforward; we’ll break down the gradient descent algorithm and show that
            it’s simply a formal representation of our intuition. The definition of the gradient descent algorithm is as follows:
          </p>

          Repeat until convergence, for j = 0 and j = 1 {
              θ_j ∶= θ_j- α ∂/(∂θ_j ) J(θ_0,θ_1)
          }

          <p>
            There are a few new terms in the gradient descent algorithm to get your head around. Before we define these new terms,
            Figure 8 presents the gradient descent algorithm with an overlay of the concepts and intuition in our mountain analogy;
            this should help provide a bit of context around how the algorithm works in practice.
          </p>

          <figure>Figure 8: The gradient descent algorithm with an overlay of the mountain analogy</figure>
          <img src="images/chapter2/figure8.png"></img>


          <div class="row mt-5">
            <div class="col-md-6 text-right pr-2"><a href="chapter01.html">&laquo; Chapter 1</a> &nbsp;&bull;</div>
            <div class="col-md-6 text-left pl-0"><a href="chapter03.html">Chapter 3 &raquo;</a></div>
          </div>
</html>
